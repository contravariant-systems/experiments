* Contravariant Systems: Build Log

** 2025-12-20: JAX Fundamentals
*** What I Built/Learnt
**** Installing JAX and development tools

There was a time when Apple had interest in maintaining a Metal
backend for JAX, which would've allowed things to be GPU accelerated
as I learnt. But that time has long passed. So for now, it's just a
[[https://docs.jax.dev/en/latest/installation.html][standard CPU install]] following the most basic steps.

In addition, I install an LSP-server and friends because it helps with
my introspection as I learn.

#+begin_src shell
python -m venv venv
pip install -U jax
pip freeze > requirements.txt
pip install -U "python-lsp-server[all]"
pip freeze > requirements-dev-tmp.txt
diff requirements-dev-tmp.txt requirements.txt | grep  '^<' | sed -e 's/< //g' > requirements-dev.txt
rm requirements-dev-tmp.txt
pip install -U matplotlib
# Then some work to update requirements.txt in the same way as above
#+end_src

Initially, I wanted to work in Emacs but getting a proper REPL with
graphics (e.g. Matplotlib) and good understanding of =venv=s was too
much.

So I moved on to Jupyter notebooks.

It was super-duper complicated to get Jupyter notebooks working
globally while seeing python packages in the VM, so I ended up just
installing jupyter lab locally. And even then, this needed to be run
in hard-coded way:

#+begin_src shell
./venv/bin/jupyter lab
#+end_src

**** Going through JAX's quickstart and related reading

I went through the following material in a file called
=quickstart.ipynb=, which introduced me to many concepts.

- https://docs.jax.dev/en/latest/notebooks/thinking_in_jax.html

In the course of this, it spidered into many, many tabs, so I followed
through most of them at least at basic level.
- https://docs.jax.dev/en/latest/key-concepts.html#jax-arrays-jax-array
- https://docs.jax.dev/en/latest/jit-compilation.html#jit-compilation
- https://docs.jax.dev/en/latest/jaxpr.html#jax-internals-jaxpr
- https://docs.jax.dev/en/latest/notebooks/Common_Gotchas_in_JAX.html
- https://docs.jax.dev/en/latest/automatic-vectorization.html
- https://docs.jax.dev/en/latest/automatic-differentiation.html
- https://docs.jax.dev/en/latest/random-numbers.html

**** Creating the most basic mechanical system to exercise JAX semantics

I then tried to recreate the most basic Hamiltonian system, the simple
harmonic oscillator using JAX and studied it a little. This works
exists in =sho.py=.

*** What Surprised Me

- How useful learning Scheme and functional-ish programming has been
  to this exercise.
- How readable (because of the above) the internal =jaxpr=
  representation is.
- How rapidly forward Euler builds up energy. Turns out this is a
  unversal thing for Hamiltonian mechanics. By the same token,
  backward Euler always loses energy.
- =jax.grad= is really cool, and it works with gradients essentially
  related to all input arguments of a function. It, by default, does
  it relative to the first one, which was confusing, but you can set
  =argnums= to a list of numbers that correspond to the positions of
  the arguments.
- It works even through what feel like weird Python containers like
  dictionaries??? (This is where my lack of knowledge of =pytrees= is
  showing.)
- More deeply though, it doesn't care whether the input is a physical
  constant or variable or something else entirely. It's just an input
  and you can differentiate relative to it. It's our human semantics
  that let us distinguish between "physical constant" and "variable to
  be learnt."

*** What Is Confusing or Didn't Work

- Emacs is not a great REPL for python.
- Jupyter and venvs are more convoluted than they should be.
- Modern JAX is not metal-accelerated on Apple Silicon macs.
- The internal representation of grad(grad(grad ... f)) gets longer
  and longer, even though at some point for a polynomial f it has gone
  to 0.
- I had to use =defaults write org.python.python ApplePersistenceIgnoreState NO=
  to prevent a very silly warning.
- JAX's JIT is quite strict about changes to shapes of things at
  runtime within the body of functions. The reason for this is that it
  "traces" the code by running it, then stores the AST to act on it
  later. If it suspects something can arbitrarily change at runtime,
  it will complain. We can either mark it is as "don't worry about it,
  this is unchanging" or reconfigure the code for shapes to be
  explicit inputs.
- I still need to better understand =jax.lax.scan=.

*** Open Questions

- How do I represent structural state and hold onto it as we go from
  symbolic to JAX (MLIR) and back.
- I really do not understand pytrees

*** Refinements to the Vision

- I am starting to see that some annotations, either at the Sympy
  level or at the JAX representation level might be what I am after.
- One example of this is =state_0= is an initial condition, and we
  need to vary this for sensitivity analysis and =m= and =k= could be
  either fixed constants or things to be learnt. Either way, the
  gradient is always available.

** 2025-12-21: Differentiating Through Dynamics
*** What I Built/Learnt
**** General insights
- In general, what is going on when constructing gradients is that the
  system is using the runtime tracing mechanism to create some sort of
  AST (=jaxpr=), and then use AD in this space to construct gradients.
- More specifically, for something like grad(final_energy) works
  relative to the initial conditions we have many, many inputs and one
  (pair of) outputs. This is best handled by reverse mode-AD. This
  means that the machinery needs to store all time-steps worth of
  forward calculations, and then use those in the backward pass as it
  accumulates gradients. This can be memory-prohibitive when there are
  too many steps involved.
- This is what we get when we discretise first then attempt to
  optimise. However, we can also attempt to do "something intelligent"
  first, then discretise. This is the path followed by the Neural ODE
  paper (Chen et al., 2018) which ends up in Diffrax.
**** Replacing the Forward Eulter integrator with Runge-Kutta 4
- It seems extremely energy conserving. This is because it is O(h^4)
  accumulation error.
- https://en.wikipedia.org/wiki/Runge–Kutta_methods

**** Proceeding to the inverse problem
Instead of simply fixing the parameters, we now assume they're unknown
and will estimate them. This begins with calculating a trajectory with
some known parameters. Then we add some noise to it and use a loss
function that has the following signature:

#+begin_src python
loss(traj_observed, state_0, n_steps, dt, params_guess)
#+end_src

i.e., it takes the made up trajectory and enough to calculate a new
trajectory with a guessed parameter. Then we can differentiate this
relative to the parameter and gradient descent our way through to the
right parameter.

***** Installing Optax

The above was done by hand, and we now install an optimising library
built on JAX: https://github.com/google-deepmind/optax

#+begin_src bash
pip install optax
diff requirements-tmp.txt requirements-dev.txt | grep '^<' | sed -e 's/< //g' > requirements.txt
#+end_src

**** Experiments with the inverse problem
- When replacing RK4 with Forward Euler, it didn't seem to make a
  massive difference.
- As the noise scale increases, the optimisers are extremely robust.
- Allowing the system to optimise for both m and k simultaneously
  cauesd it to find whatever random values (k was close to the true
  value) that sort of fit.
*** What Surprised Me
- Looking at the =jaxpr=s for things is a way to understand what is
  going on. e.g. Specifically in some sort of differentiation over a
  loop sense, a single scan (fold) corresponds to two in the internal
  representation. Notice that one is forward =reverse=False= and one
  is reverse.

#+begin_src
    _:f32[2] _:f32[] g:f32[5,2] = scan[
      _split_transpose=False
      jaxpr={ lambda ; h:f32[] i:f32[] j:f32[2] k:f32[]. let
          l:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] j
          m:f32[] = squeeze[dimensions=(0,)] l
          n:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] j
          o:f32[] = squeeze[dimensions=(0,)] n
          p:f32[] = div o h
          q:f32[] = mul i m
          r:f32[1] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(1,)
            sharding=None
          ] p
          s:f32[1] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(1,)
            sharding=None
          ] q
          t:f32[2] = concatenate[dimension=0] r s
          u:f32[2] = mul 0.009999999776482582:f32[] t
          v:f32[2] = add j u
          w:f32[] = add k 0.01:f32[]
        in (v, w, v) }
      length=5
      linear=(False, False, False, False)
      num_carry=2
      num_consts=2
      reverse=False
      unroll=1
    ] d f a 0.0:f32[]

    cg:f32[2] = scan[
      _split_transpose=False
      jaxpr={ lambda ; ch:f32[] ci:f32[] cj:f32[2] ck:f32[2]. let
          cl:f32[2] = add_any cj ck
          cm:f32[2] = mul 0.009999999776482582:f32[] cl
          cn:f32[1] co:f32[1] = split[axis=0 sizes=(1, 1)] cm
          cp:f32[] = reduce_sum[axes=(np.int64(0),) out_sharding=None] co
          cq:f32[] = reduce_sum[axes=(np.int64(0),) out_sharding=None] cn
          cr:f32[] = mul ci cp
          cs:f32[] = div cq ch
          ct:f32[1] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(1,)
            sharding=None
          ] cs
          cu:f32[2] = pad[padding_config=((1, np.int64(0), 0),)] ct 0.0:f32[]
          cv:f32[2] = add_any cl cu
          cw:f32[1] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(1,)
            sharding=None
          ] cr
          cx:f32[2] = pad[padding_config=((0, np.int64(1), 0),)] cw 0.0:f32[]
          cy:f32[2] = add_any cv cx
        in (cy,) }
      length=5
      linear=(False, False, True, True)
      num_carry=1
      num_consts=2
      reverse=True
      unroll=1
    ] d f cf ce
  #+end_src
- Runge-Kutta (RK4) is astonishingly good at conserving energy. After
  100000 steps, it's off by O(1.e-6).
- I can crank up noise levels on a trajectory to really high (like
  =noise_scale=500=) and not have the optimisers fail to find =k=.
- What was really, really cool is that the dynamics of the system only
  depend on =sqrt(k/m)=. So when optimising for =k= and =m=
  simultaneously, even though =m= didn't stay fixed, the ratio of
  these two were bang on at the reference values.
*** What Is Confusing or Didn't Work
**** Loss functions seem kinda arbitrary
They are scalars that depend on some sort of unsigned distance to some
truth, but it feels quite unphysical to me to arbitrarily add
quantities of different types into one scalar.
**** =jax.linalg.norm= with =ord=2= gets the wrong gradient sign
I need to better understand how the norm is defined, and I need to
understand why it was messing with the sign of the gradient of the
loss.
**** The Adam optimiser is quite finicky
- To freeze parameters, we need to mark them with =True=.
- With a low learning rate, convergence was super slow. Then with a
  higher rate, it converged rapidly but oscillated. Standard gradient
  descent was so much smoother.
*** Open Questions
*** Refinements to the Vision
- We need to enforce what is known, otherwise we will find equivalent
  solutions if a problem is undefined.
** 2025-12-22: Sympy to JAX Bridge

This is the core of Contravariant's architecture: symbolic
specification → compiled numerics.

*** What I Built/Learnt
**** Went through the introductory documentation on Sympy
- https://docs.sympy.org/latest/tutorials/intro-tutorial/index.html
- https://docs.sympy.org/latest/tutorials/intro-tutorial/gotchas.html
- https://docs.sympy.org/latest/explanation/gotchas.html#gotchas
- https://docs.sympy.org/latest/tutorials/intro-tutorial/basic_operations.html
- The outcome of these experiments went into =sympy-quickstart.ipynb=.
***** Installing Sympy
#+begin_src bash
pip install sympy
pip freeze > requirements-tmp.txt
diff requirements-tmp.txt requirements-dev.txt | grep '^<' | sed -e 's/< //g' > requirements.txt
rm requirements-tmp.txt
#+end_src

Remember that we need to start it with the local =sympy=.

#+begin_src bash
./venv/bin/jupyter lab
#+end_src
***** Converting from Sympy to Numpy

This is the crux of the conversion. In =sympy=, you can go from plain
text to sympy expressions with =sympify()=. And when you need to
evaluate things, you can use =subs()= followed by =evalf()= but this
is not fast.

What we actually want to do is to convert from a =sympy=
representation to a more standard Python (=numpy=) function
representation, which can then be easily applied to a large set of
input numbers.

This essentially just converts names of things to be relevant to where
you're going to use the function. In general, SymPy functions do not
work with objects from other libraries, such as NumPy arrays, and
functions from numeric libraries like NumPy or mpmath do not work on
SymPy expressions. =lambdify= bridges the two by converting a SymPy
expression to an equivalent numeric function.

#+begin_src python
a = numpy.arange(20)
expr = sin(x)
f = lambdify(x, expr, "numpy")
f(a)
#+end_src

**** Describing the physics in terms of Lagrangians in Sympy
This was fairly straightforward, and compared very favourably with
doing it by hand.
*** What Surprised Me
- Turns out it is undecidable as to whether two symbolic expressions
  are always equal to each other:
  https://en.wikipedia.org/wiki/Richardson%27s_theorem
- This is the deepest thing I learnt today. When we define a
  Lagrangian, it is a function on state space, i.e. it is
  parameterised by the the space of =(q, q_qdot)= pairs. You can ask
  it questions like, given a position and a velocity, what is the
  Lagrangian?

  Notice you are making no claims as to whether this is a valid
  trajectory in terms of satisfying any physics. It's just a function
  in 2D space. In this context, =q= and =q_dot= are independent
  variables, and independent of one another.

  Once you've figured out a specific trajectory =q(t)=, then
  =q_dot(t)= is fully defined as just the time derivative of =q=. In
  this context, they are no longer independent.

  Now the genius bit here is that it's the Euler-Lagrange equation
  that lives in the boundary between these two contexts. The partial
  derivatives in the equation =dL/dq= and =dL/dq_dot= are evaluated
  in the first (independent) context but the total time derivative is
  evaluated in the second context (along a trajectory)!

  The Euler-Lagrange equation is the stationarity condition, i.e.
  given we're constrained to paths where the velocity is the time
  derivative of the position, which paths make the action stationary.

  The variational principle selects, from all possible paths, those
  that are physically realisable, where the velocity really is the
  derivative of position, and the acceleration really is what the
  forces dictate. Oh my god.
- The move from using Hamiltonians =(q, p)= to Lagrangians =(q,
  q_dot)= was almost trivial in the numerical integrator code. In both
  cases, we are trying to evolve the state in state space with the
  dynamics being defined in terms of the time derivative of this. I
  expected more work in breaking up the second-order polynomial into
  two first order ones.

*** What Is Confusing or Didn't Work
It was really, really hard to work with trajectory-matching loss
functions. This means that it's really hard to solve optimisation
problems quickly and generally in this space. There appear to be a lot
of local minima.

*** Open Questions
- I still need to understand where in the sympy -> jax representation
  (a sidecar dictionary?) that I store physics insights about where
  terms come from.
*** Refinements to the Vision
The core of the idea looks something like:

#+begin_src python
# Symbolic specification
L = Rational(1,2)*m*(q1_dot**2 + q2_dot**2) - Rational(1,2)*k*(q1**2 + q2**2)

# Structural analysis (Euler-Lagrange)
eom = derive_equations_of_motion(L, [q1, q2], [q1_dot, q2_dot])

# Code generation
dynamics = make_dynamics_from_eom(eom)

# Compiled, differentiable simulation
traj = integrate_rk4(state_0, n_steps, dt, params, dynamics)

# Learning
grad_loss = grad(loss, argnums=4)(traj_observed, ..., dynamics)
#+end_src
