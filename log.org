* Contravariant Systems: Build Log

** 2025-12-20: JAX Fundamentals
*** What I Built/Learnt
**** Installing JAX and development tools

There was a time when Apple had interest in maintaining a Metal
backend for JAX, which would've allowed things to be GPU accelerated
as I learnt. But that time has long passed. So for now, it's just a
[[https://docs.jax.dev/en/latest/installation.html][standard CPU install]] following the most basic steps.

In addition, I install an LSP-server and friends because it helps with
my introspection as I learn.

#+begin_src shell
python -m venv venv
pip install -U jax
pip freeze > requirements.txt
pip install -U "python-lsp-server[all]"
pip freeze > requirements-dev-tmp.txt
diff requirements-dev-tmp.txt requirements.txt | grep  '^<' | sed -e 's/< //g' > requirements-dev.txt
rm requirements-dev-tmp.txt
pip install -U matplotlib
# Then some work to update requirements.txt in the same way as above
#+end_src

Initially, I wanted to work in Emacs but getting a proper REPL with
graphics (e.g. Matplotlib) and good understanding of =venv=s was too
much.

So I moved on to Jupyter notebooks.

It was super-duper complicated to get Jupyter notebooks working
globally while seeing python packages in the VM, so I ended up just
installing jupyter lab locally. And even then, this needed to be run
in hard-coded way:

#+begin_src shell
./venv/bin/jupyter lab
#+end_src

**** Going through JAX's quickstart and related reading

I went through the following material in a file called
=quickstart.ipynb=, which introduced me to many concepts.

- https://docs.jax.dev/en/latest/notebooks/thinking_in_jax.html

In the course of this, it spidered into many, many tabs, so I followed
through most of them at least at basic level.
- https://docs.jax.dev/en/latest/key-concepts.html#jax-arrays-jax-array
- https://docs.jax.dev/en/latest/jit-compilation.html#jit-compilation
- https://docs.jax.dev/en/latest/jaxpr.html#jax-internals-jaxpr
- https://docs.jax.dev/en/latest/notebooks/Common_Gotchas_in_JAX.html
- https://docs.jax.dev/en/latest/automatic-vectorization.html
- https://docs.jax.dev/en/latest/automatic-differentiation.html
- https://docs.jax.dev/en/latest/random-numbers.html

**** Creating the most basic mechanical system to exercise JAX semantics

I then tried to recreate the most basic Hamiltonian system, the simple
harmonic oscillator using JAX and studied it a little. This works
exists in =sho.py=.

*** What Surprised Me

- How useful learning Scheme and functional-ish programming has been
  to this exercise.
- How readable (because of the above) the internal =jaxpr=
  representation is.
- How rapidly forward Euler builds up energy. Turns out this is a
  unversal thing for Hamiltonian mechanics. By the same token,
  backward Euler always loses energy.
- =jax.grad= is really cool, and it works with gradients essentially
  related to all input arguments of a function. It, by default, does
  it relative to the first one, which was confusing, but you can set
  =argnums= to a list of numbers that correspond to the positions of
  the arguments.
- It works even through what feel like weird Python containers like
  dictionaries??? (This is where my lack of knowledge of =pytrees= is
  showing.)
- More deeply though, it doesn't care whether the input is a physical
  constant or variable or something else entirely. It's just an input
  and you can differentiate relative to it. It's our human semantics
  that let us distinguish between "physical constant" and "variable to
  be learnt."

*** What Is Confusing or Didn't Work

- Emacs is not a great REPL for python.
- Jupyter and venvs are more convoluted than they should be.
- Modern JAX is not metal-accelerated on Apple Silicon macs.
- The internal representation of grad(grad(grad ... f)) gets longer
  and longer, even though at some point for a polynomial f it has gone
  to 0.
- I had to use =defaults write org.python.python ApplePersistenceIgnoreState NO=
  to prevent a very silly warning.
- JAX's JIT is quite strict about changes to shapes of things at
  runtime within the body of functions. The reason for this is that it
  "traces" the code by running it, then stores the AST to act on it
  later. If it suspects something can arbitrarily change at runtime,
  it will complain. We can either mark it is as "don't worry about it,
  this is unchanging" or reconfigure the code for shapes to be
  explicit inputs.
- I still need to better understand =jax.lax.scan=.

*** Open Questions

- How do I represent structural state and hold onto it as we go from
  symbolic to JAX (MLIR) and back.
- I really do not understand pytrees

*** Refinements to the Vision

- I am starting to see that some annotations, either at the Sympy
  level or at the JAX representation level might be what I am after.
- One example of this is =state_0= is an initial condition, and we
  need to vary this for sensitivity analysis and =m= and =k= could be
  either fixed constants or things to be learnt. Either way, the
  gradient is always available.

** 2025-12-21: Differentiating Through Dynamics
*** What I Built/Learnt
**** General insights
- In general, what is going on when constructing gradients is that the
  system is using the runtime tracing mechanism to create some sort of
  AST (=jaxpr=), and then use AD in this space to construct gradients.
- More specifically, for something like grad(final_energy) works
  relative to the initial conditions we have many, many inputs and one
  (pair of) outputs. This is best handled by reverse mode-AD. This
  means that the machinery needs to store all time-steps worth of
  forward calculations, and then use those in the backward pass as it
  accumulates gradients. This can be memory-prohibitive when there are
  too many steps involved.
- This is what we get when we discretise first then attempt to
  optimise. However, we can also attempt to do "something intelligent"
  first, then discretise. This is the path followed by the Neural ODE
  paper (Chen et al., 2018) which ends up in Diffrax.
**** Replacing the Forward Eulter integrator with Runge-Kutta 4
- It seems extremely energy conserving. This is because it is O(h^4)
  accumulation error.
- https://en.wikipedia.org/wiki/Runge–Kutta_methods

**** Proceeding to the inverse problem
Instead of simply fixing the parameters, we now assume they're unknown
and will estimate them. This begins with calculating a trajectory with
some known parameters. Then we add some noise to it and use a loss
function that has the following signature:

#+begin_src python
loss(traj_observed, state_0, n_steps, dt, params_guess)
#+end_src

i.e., it takes the made up trajectory and enough to calculate a new
trajectory with a guessed parameter. Then we can differentiate this
relative to the parameter and gradient descent our way through to the
right parameter.

***** Installing Optax

The above was done by hand, and we now install an optimising library
built on JAX: https://github.com/google-deepmind/optax

#+begin_src bash
pip install optax
diff requirements-tmp.txt requirements-dev.txt | grep '^<' | sed -e 's/< //g' > requirements.txt
#+end_src

**** Experiments with the inverse problem
- When replacing RK4 with Forward Euler, it didn't seem to make a
  massive difference.
- As the noise scale increases, the optimisers are extremely robust.
- Allowing the system to optimise for both m and k simultaneously
  cauesd it to find whatever random values (k was close to the true
  value) that sort of fit.
*** What Surprised Me
- Looking at the =jaxpr=s for things is a way to understand what is
  going on. e.g. Specifically in some sort of differentiation over a
  loop sense, a single scan (fold) corresponds to two in the internal
  representation. Notice that one is forward =reverse=False= and one
  is reverse.

#+begin_src
    _:f32[2] _:f32[] g:f32[5,2] = scan[
      _split_transpose=False
      jaxpr={ lambda ; h:f32[] i:f32[] j:f32[2] k:f32[]. let
          l:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] j
          m:f32[] = squeeze[dimensions=(0,)] l
          n:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] j
          o:f32[] = squeeze[dimensions=(0,)] n
          p:f32[] = div o h
          q:f32[] = mul i m
          r:f32[1] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(1,)
            sharding=None
          ] p
          s:f32[1] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(1,)
            sharding=None
          ] q
          t:f32[2] = concatenate[dimension=0] r s
          u:f32[2] = mul 0.009999999776482582:f32[] t
          v:f32[2] = add j u
          w:f32[] = add k 0.01:f32[]
        in (v, w, v) }
      length=5
      linear=(False, False, False, False)
      num_carry=2
      num_consts=2
      reverse=False
      unroll=1
    ] d f a 0.0:f32[]

    cg:f32[2] = scan[
      _split_transpose=False
      jaxpr={ lambda ; ch:f32[] ci:f32[] cj:f32[2] ck:f32[2]. let
          cl:f32[2] = add_any cj ck
          cm:f32[2] = mul 0.009999999776482582:f32[] cl
          cn:f32[1] co:f32[1] = split[axis=0 sizes=(1, 1)] cm
          cp:f32[] = reduce_sum[axes=(np.int64(0),) out_sharding=None] co
          cq:f32[] = reduce_sum[axes=(np.int64(0),) out_sharding=None] cn
          cr:f32[] = mul ci cp
          cs:f32[] = div cq ch
          ct:f32[1] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(1,)
            sharding=None
          ] cs
          cu:f32[2] = pad[padding_config=((1, np.int64(0), 0),)] ct 0.0:f32[]
          cv:f32[2] = add_any cl cu
          cw:f32[1] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(1,)
            sharding=None
          ] cr
          cx:f32[2] = pad[padding_config=((0, np.int64(1), 0),)] cw 0.0:f32[]
          cy:f32[2] = add_any cv cx
        in (cy,) }
      length=5
      linear=(False, False, True, True)
      num_carry=1
      num_consts=2
      reverse=True
      unroll=1
    ] d f cf ce
  #+end_src
- Runge-Kutta (RK4) is astonishingly good at conserving energy. After
  100000 steps, it's off by O(1.e-6).
- I can crank up noise levels on a trajectory to really high (like
  =noise_scale=500=) and not have the optimisers fail to find =k=.
- What was really, really cool is that the dynamics of the system only
  depend on =sqrt(k/m)=. So when optimising for =k= and =m=
  simultaneously, even though =m= didn't stay fixed, the ratio of
  these two were bang on at the reference values.
*** What Is Confusing or Didn't Work
**** Loss functions seem kinda arbitrary
They are scalars that depend on some sort of unsigned distance to some
truth, but it feels quite unphysical to me to arbitrarily add
quantities of different types into one scalar.
**** =jax.linalg.norm= with =ord=2= gets the wrong gradient sign
I need to better understand how the norm is defined, and I need to
understand why it was messing with the sign of the gradient of the
loss.
**** The Adam optimiser is quite finicky
- To freeze parameters, we need to mark them with =True=.
- With a low learning rate, convergence was super slow. Then with a
  higher rate, it converged rapidly but oscillated. Standard gradient
  descent was so much smoother.
*** Open Questions
*** Refinements to the Vision
- We need to enforce what is known, otherwise we will find equivalent
  solutions if a problem is undefined.
** 2025-12-22: Sympy to JAX Bridge

This is the core of Contravariant's architecture: symbolic
specification → compiled numerics.

*** What I Built/Learnt
**** Went through the introductory documentation on Sympy
- https://docs.sympy.org/latest/tutorials/intro-tutorial/index.html
- https://docs.sympy.org/latest/tutorials/intro-tutorial/gotchas.html
- https://docs.sympy.org/latest/explanation/gotchas.html#gotchas
- https://docs.sympy.org/latest/tutorials/intro-tutorial/basic_operations.html
- The outcome of these experiments went into =sympy-quickstart.ipynb=.
***** Installing Sympy
#+begin_src bash
pip install sympy
pip freeze > requirements-tmp.txt
diff requirements-tmp.txt requirements-dev.txt | grep '^<' | sed -e 's/< //g' > requirements.txt
rm requirements-tmp.txt
#+end_src

Remember that we need to start it with the local =sympy=.

#+begin_src bash
./venv/bin/jupyter lab
#+end_src
***** Converting from Sympy to Numpy

This is the crux of the conversion. In =sympy=, you can go from plain
text to sympy expressions with =sympify()=. And when you need to
evaluate things, you can use =subs()= followed by =evalf()= but this
is not fast.

What we actually want to do is to convert from a =sympy=
representation to a more standard Python (=numpy=) function
representation, which can then be easily applied to a large set of
input numbers.

This essentially just converts names of things to be relevant to where
you're going to use the function. In general, SymPy functions do not
work with objects from other libraries, such as NumPy arrays, and
functions from numeric libraries like NumPy or mpmath do not work on
SymPy expressions. =lambdify= bridges the two by converting a SymPy
expression to an equivalent numeric function.

#+begin_src python
a = numpy.arange(20)
expr = sin(x)
f = lambdify(x, expr, "numpy")
f(a)
#+end_src

**** Describing the physics in terms of Lagrangians in Sympy
This was fairly straightforward, and compared very favourably with
doing it by hand.
*** What Surprised Me
- Turns out it is undecidable as to whether two symbolic expressions
  are always equal to each other:
  https://en.wikipedia.org/wiki/Richardson%27s_theorem
- This is the deepest thing I learnt today. When we define a
  Lagrangian, it is a function on state space, i.e. it is
  parameterised by the the space of =(q, q_qdot)= pairs. You can ask
  it questions like, given a position and a velocity, what is the
  Lagrangian?

  Notice you are making no claims as to whether this is a valid
  trajectory in terms of satisfying any physics. It's just a function
  in 2D space. In this context, =q= and =q_dot= are independent
  variables, and independent of one another.

  Once you've figured out a specific trajectory =q(t)=, then
  =q_dot(t)= is fully defined as just the time derivative of =q=. In
  this context, they are no longer independent.

  Now the genius bit here is that it's the Euler-Lagrange equation
  that lives in the boundary between these two contexts. The partial
  derivatives in the equation =dL/dq= and =dL/dq_dot= are evaluated
  in the first (independent) context but the total time derivative is
  evaluated in the second context (along a trajectory)!

  The Euler-Lagrange equation is the stationarity condition, i.e.
  given we're constrained to paths where the velocity is the time
  derivative of the position, which paths make the action stationary.

  The variational principle selects, from all possible paths, those
  that are physically realisable, where the velocity really is the
  derivative of position, and the acceleration really is what the
  forces dictate. Oh my god.
- The move from using Hamiltonians =(q, p)= to Lagrangians =(q,
  q_dot)= was almost trivial in the numerical integrator code. In both
  cases, we are trying to evolve the state in state space with the
  dynamics being defined in terms of the time derivative of this. I
  expected more work in breaking up the second-order polynomial into
  two first order ones.

*** What Is Confusing or Didn't Work
It was really, really hard to work with trajectory-matching loss
functions. This means that it's really hard to solve optimisation
problems quickly and generally in this space. There appear to be a lot
of local minima.

*** Open Questions
- I still need to understand where in the sympy -> jax representation
  (a sidecar dictionary?) that I store physics insights about where
  terms come from.
*** Refinements to the Vision
The core of the idea looks something like:

#+begin_src python
# Symbolic specification
L = Rational(1,2)*m*(q1_dot**2 + q2_dot**2) - Rational(1,2)*k*(q1**2 + q2**2)

# Structural analysis (Euler-Lagrange)
eom = derive_equations_of_motion(L, [q1, q2], [q1_dot, q2_dot])

# Code generation
dynamics = make_dynamics_from_eom(eom)

# Compiled, differentiable simulation
traj = integrate_rk4(state_0, n_steps, dt, params, dynamics)

# Learning
grad_loss = grad(loss, argnums=4)(traj_observed, ..., dynamics)
#+end_src
** 2025-12-23: Structure-Preserving Integration

RK4 is accurate but not structure-preserving. Over long times, it
drifts. Today we built an integrator that respects the geometry of
Hamiltonian mechanics.

Compare gradient quality: does structure preservation help learning?

*** What I Built/Learnt
**** Reading up about integrators for Hamiltonian systems
- https://en.wikipedia.org/wiki/Symplectic_integrator

  Symplectic integrators possess, as a conserved quantity, a
  Hamiltonian which is slightly perturbed from the original one. By
  virtue of these advantages, the SI scheme has been widely applied to
  the calculations of long-term evolution of chaotic Hamiltonian
  systems ranging from the Kepler problem to the classical and
  semi-classical simulations in molecular dynamics.

  Most of the usual numerical methods, such as the primitive Euler
  scheme and the classical Runge–Kutta scheme, are not symplectic
  integrators.

- https://en.wikipedia.org/wiki/Symplectic_integrator
- https://en.wikipedia.org/wiki/Verlet_integration

  The Verlet integrator provides good numerical stability, as well as
  other properties that are important in physical systems such as time
  reversibility and preservation of the symplectic form on phase
  space, at no significant additional computational cost over the
  simple Euler method.

  The form we end up using is called the Velocity Verlet.

- https://link.springer.com/book/10.1007/3-540-30666-8
- https://www.unige.ch/~hairer/poly_geoint/week1.pdf
- https://mitp-content-server.mit.edu/books/content/sectbyfn/books_pres_0/9579/sicm_edition_2.zip/chapter003.html#h1-18

  Our motivation for the development of Hamilton’s equations was to
  focus attention on the quantities that can be conserved—the momenta
  and the energy. In the Hamiltonian formulation the generalized
  configuration coordinates and the conjugate momenta comprise the
  state of the system at a given time. We know from the Lagrangian
  formulation that if the Lagrangian does not depend on some
  coordinate then the conjugate momentum is conserved. This is also
  true in the Hamiltonian formulation, but there is a distinct
  advantage to the Hamiltonian formulation. In the Lagrangian
  formulation the knowledge of the conserved momentum does not lead
  immediately to any simplification of the problem, but in the
  Hamiltonian formulation the fact that momenta are conserved gives an
  immediate reduction in the dimension of the system to be solved. In
  fact, if a coordinate does not appear in the Hamiltonian then the
  dimension of the system of coupled equations that remain to be
  solved is reduced by two: the coordinate does not appear and the
  conjugate momentum is constant.

- https://mitp-content-server.mit.edu/books/content/sectbyfn/books_pres_0/9579/sicm_edition_2.zip/chapter004.html
- https://scicomp.stackexchange.com/questions/29149/what-does-symplectic-mean-in-reference-to-numerical-integrators-and-does-scip
**** Some other things I learnt in my reading
***** What is the symplectic 2-form and why does preserving it matter?
The symplectic 2-form \omega is the intrinsic geometric structure of
phase space that turns dH into dynamics and defines the
Poisson/bracket/area geometry; preserving it means the evolution is a
true Hamiltonian transformation—volume- and structure-preserving—so it
keeps the system’s qualitative mechanics faithful, especially over
long times.

***** What does "bounded energy error" mean precisely?
As we run a symplectic integrator over time, the deviation
H(z_n)-H(z_0) stays uniformly bounded in n (typically by something
small in h), rather than accumulating unboundedly with time. The
bounded error isn't just bounded—it's /oscillatory/. The integrator
exactly preserves a slightly perturbed Hamiltonian H~=H+O(hk)\tilde{H}
= H + O(h^k) H~=H+O(hk), so the true energy oscillates around the
initial value rather than drifting in one direction.

***** Why does Verlet work for separable Hamiltonians specifically?
Verlet’s magic is that separability gives you two exact, cheap
Hamiltonian flows (“kick” and “drift”), and Verlet is the symmetric
composition that keeps the geometry.

***** What goes wrong for non-separable Hamiltonians?

Verlet’s whole construction relies on the existence of two exact,
explicit, symplectic subflows. Non-separability destroys that, and
naive adaptations typically stop being symplectic and start drifting
qualitatively over long times. You will need other constructions like
symplectic versions of Runge-Kutta.

**** Completely reorganised the code
Separated the code out into a core module that can be included and
reused.

#+begin_src bash
contravariant
├── __init__.py
├── codegen.py
├── integrators.py
├── learning.py
├── plotting.py
└── symbolic.py
#+end_src

But in doing this, the language model generated all the code for the
different sections, so need to proofread and polish it.

**** Studying Verlet vs RK4 in different circumstances
With the newly modularised code, it was very easy to run the:

- Simple harmonic oscillator
- 2D Isotropic oscillator
- Coupled oscillator

For small dt and moderate times, RK4's higher accuracy dominates. The
symplectic advantage shows when:

- Long times: drift accumulates
- Larger timesteps: accuracy per step matters less, structure matters more
- Chaotic systems: where small errors compound exponentially

**** Studying the non-separable case

Verlet requires H = T(p) + V(q) (separable). We then try the double
pendulum where this condition is not met.

First, the system is smart enough to recognise this(!) when it figures
out that the terms in the Lagrangian are not separable. This is good
for Contravariant as this is the sort of thing we will use to identify
methods.

But when we run it via Verlet anyway on the non-separable double
pendulum problem, it still tries to oscillate about something, except
it's the wrong solution.

In summary:

- Coupling in V(q): fine for Verlet. The potential can mix positions
  however it wants.
- Coupling in T(q,p): breaks Verlet. The kinetic energy must be
  T(p) only.

**** Where structure preservation does help learning?
- Learning from conserved quantities: If you match energy instead of
  trajectory, Verlet's bounded energy error means the loss surface is
  smoother.
- Long-horizon prediction: If you're learning a model to predict far
  into the future, Verlet won't accumulate drift that corrupts your
  training signal.
- Chaotic systems: RK4 on a chaotic system gives nonsense gradients
  after the Lyapunov time. Verlet at least preserves the statistical
  structure.

The deeper point: structure preservation helps when your loss function
respects the structure. Trajectory matching doesn't. Energy matching
does

*** What Surprised Me
- Verlet exactly preserves a nearby Hamiltonian H~=H+O(h2)\tilde{H} =
  H + O(h^2) H~=H+O(h2), so the true energy oscillates around the
  initial value. RK4 preserves nothing, it's just accurate, and
  accuracy isn't enough.

*** What Is Confusing or Didn't Work
- It is not easy to calculate the area of phase space cloud plots, so
  it's not easy to carefully verify the area conserving properties of
  symplectic integrators.
- For trajectory matching with oscillatory systems, the loss landscape is:
  - Non-convex: multiple minima
  - Periodic: phase shifts create repeating patterns of good/bad fits
  - Sensitive to initial guesses
  So it's actually quite hard to use standard gradient descent and
  trust the sign of the gradient at any given guess.

*** Open Questions

- I have fetched a copy of a book called "Geometric Numerical
  Integration" that I need to make time to read. It is well reviewed.
- I need to read SICM much more carefully, now that I understand
  Scheme a lot better. Possibly redo parts of it in JAX.

*** Refinements to the Vision
- We don't penalise the drift. We chose an integrator that
  geometrically /cannot/ drift.
** 2025-12-24: Noether's Theorem as an Algorithm
Today, we use Noether's theorem to identify what quantities ought to
be conserved, and verify them numerically. We then use these
quantities to completely change the game on parameter discovery.

*** What I Built/Learnt
**** Reading about Noether's theorem
- https://en.wikipedia.org/wiki/Noether%27s_theorem

  Noether’s theorem says that for a system with conservative forces
  (described by an action/Lagrangian), every continuous, smooth
  symmetry of the action implies a corresponding conserved quantity.
  It underpins much of modern theoretical physics by linking
  symmetries to conservation laws, but it generally doesn’t apply to
  dissipative (non-conservative) systems where a Lagrangian alone
  isn’t enough.

  And because it makes these connections, you can e.g. use the
  knowledge that something is conserved to restrict/suggest functional
  forms of the Lagrangian. (Similarly the other way around, of course.)

  Specifically:

  - Time translation → energy
  - Space translation → momentum
  - Rotation → angular momentum
- https://mitp-content-server.mit.edu/books/content/sectbyfn/books_pres_0/9579/sicm_edition_2.zip/chapter001.html#h1-6c
- https://en.wikipedia.org/wiki/Lagrangian_mechanics#Cyclic_coordinates_and_conserved_momenta

  If a generalised coordinate is not present in the functional form of
  the Lagrangian, it's corresponding conjugate momentum is conserved.
**** Some salient points
***** Noether's Theorem: Key Concepts
****** Cyclic coordinates (simplest case)
If $\frac{\partial L}{\partial q_i} = 0$, coordinate $q_i$ doesn't
appear in $L$. This is a symmetry: translations in $q_i$ leave physics
unchanged. The conjugate momentum $p_i = \frac{\partial L}{\partial
\dot{q}_i}$ is conserved.

****** General symmetries
A continuous symmetry is a direction you can "nudge" the trajectory
without changing the action. The conserved quantity is the projection
of the system's momenta onto the symmetry's infinitesimal generator:
$$Q = \sum_i p_i \xi_i$$ where $\xi_i =
\frac{d}{ds}F_s(q_i)\big|_{s=0}$ is the generator.

****** 3. Why energy is special
- Space translation ($x \to x + \epsilon$): conserves momentum
  (component of motion in that direction)
- Time translation ($t \to t + \epsilon$): conserves energy (the
  Hamiltonian)

Energy is tied to invariance under "when"—whether $L$ has explicit
time dependence. Break that, and energy conservation fails.

***** SICM's approach
- Lagrangian as a procedure on local state $(t, q, \dot{q})$
- Operators that differentiate symbolically
- For Noether: provide transformation family $F_s$, differentiate at
  $s=0$ to get generator $\xi$, compute $p \cdot \xi$

**** Expanding the symbolic mechanics with some numerical verification
***** Detecting cyclic coordinates
This is really straightforward. We just loop over all the coordinates
and take the derivative of L with respect to each of them. We can
easily identify all of the cases where the derivative is 0.

Except it's not as trivial because telling if an expression is 0 is
not decidable.
***** Deriving the Hamiltonian from the Lagrangian
This is a straightforward Legendre transform.
***** Find the quantity conserved by a symmetry
Given an infinitesimal generator, ξ, compute the Noether charge (the
conserved quantity). Then we systematically and numerically verified
this on a real trajectory.
***** Time translation is special
We verified this numerically in Day 4.
**** The clear pattern for specifying a symmetry

1. Write the finite transformation $q \to F_\epsilon(q)$
2. Expand to first order in $\epsilon$
3. Extract the coefficient: $\xi = \frac{d}{d\epsilon}F_\epsilon(q)\big|_{\epsilon=0}$

For translation in $x$: $F_\epsilon(x) = x + \epsilon$, so $\xi = (1, 0)$.

For rotation: $\xi = (-y, x)$.
**** Trying for loss functions that are more robust than trajectory differences
In the previous days, I have struggled with the flakiness of parameter
estimation based on a loss function that was a squared
trajectory-difference.

Today, instead of matching trajectories point-by-point, I try to match
by statistics that don't depend on phase. And it worked gloriously!
*** What Surprised Me
- It's non-trivial (and in fact undecidable) as to whether we can tell
  if a generic expression is 0. This is Richardson's theorem from Day
  3, but I was reminded of it again.
- With Verlet integration in the 2D oscillator example, angular
  momentum error was bounded at O(1e-5) over 10 million steps. The
  oscillatory, non-drifting character showed the symplectic integrator
  respecting the structure.
- Using an energy statistic made the parameter discovery so much
  faster. Physics tells us what is invariant. And we use that
  invariance in our loss function, and the optimisation landscape
  respects the physics instead of fighting it.

  This was the most glorious finding of the day.
*** What Is Confusing or Didn't Work
- I am not completely confident on how to specify the infinitesimal
  generator, ξ. I have a general pattern now, but I need to study it
  further with more complex examples.
*** Open Questions
- It's interesting to me how all of this theory is in
  conservative/non-dissipative systems. I am curious how it extends to
  realistic systems.
*** Refinements to the Vision
- It's clearer I need a =System= object that carries the Lagrangian
  and its derived structure together.
